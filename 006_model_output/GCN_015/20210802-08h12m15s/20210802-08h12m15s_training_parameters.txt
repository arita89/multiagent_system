input_file_name: df_balanced_30480_normalized
max_num_veh: 10
sim_duration_timesteps: 30480
run_date: 20210802-
run_time: 08h12m15s
model: GCN_015
combo: ('sum', 256, 'Adam', 'L1', [64, 128], 0.001, 0.6, 0, 'CosineAnnealingWarmRestarts', True, 'leaky_relu')
random_seed: 42
train_size: 0.9
batch_size: 256
Nepochs: 2000
save_every: 200
transformstat: False
plotstat: True
printstat: False
intentionstat: obsoleted
use_edges_attr: True
activation_function: leaky_relu
shuttle_train_frame: 11164
shuttle_val_frame: 13416
num_rows_training: 27432
num_rows_validation: 2743
num_rows_test: 305
exclude_yaw: obsoleted
concatenatestat: obsoleted
paddingstat: obsoleted
size_input: 6
size_output: 2
model_architecture: GCN_HL02_bn_relu(
  (conv1): GraphConv(6, 64)
  (conv2): GraphConv(64, 128)
  (conv3): GraphConv(128, 2)
  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): LeakyReLU(negative_slope=0.01)
)
hidden_layers_sizes: [64, 128]
criterion: L1Loss()
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.001
    lr: 5.318367983829381e-05
    weight_decay: 0
)
reduction: sum
scheduler: CosineAnnealingWarmRestarts
model_path: /storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/20210802-08h12m15sEPOCH_2000of2000_FINAL__GCN_015.pt
train_losses_path: /storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/20210802-08h12m15sEPOCH_2000of2000_FINAL__FINAL__training_loss.pkl
val_losses_path: /storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/20210802-08h12m15sEPOCH_2000of2000_FINAL__FINAL__validation_loss.pkl
lr_path: /storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/20210802-08h12m15sEPOCH_2000of2000_FINAL__FINAL__learning_rate.pkl
epoch200_train_loss: 3111.075213396991
epoch200_final_val_loss: 4512.353071732955
figure_paths: ['/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_training_set/20210802-08h12m15sModel_GCN_015_shuttle_train_epoch_000200of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_validation_set/20210802-08h12m15sModel_GCN_015_shuttle_val_epoch_000200of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_training_set/20210802-08h12m15sModel_GCN_015_shuttle_train_epoch_000400of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_validation_set/20210802-08h12m15sModel_GCN_015_shuttle_val_epoch_000400of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_training_set/20210802-08h12m15sModel_GCN_015_shuttle_train_epoch_000600of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_validation_set/20210802-08h12m15sModel_GCN_015_shuttle_val_epoch_000600of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_training_set/20210802-08h12m15sModel_GCN_015_shuttle_train_epoch_000800of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_validation_set/20210802-08h12m15sModel_GCN_015_shuttle_val_epoch_000800of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_training_set/20210802-08h12m15sModel_GCN_015_shuttle_train_epoch_001000of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_validation_set/20210802-08h12m15sModel_GCN_015_shuttle_val_epoch_001000of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_training_set/20210802-08h12m15sModel_GCN_015_shuttle_train_epoch_001200of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_validation_set/20210802-08h12m15sModel_GCN_015_shuttle_val_epoch_001200of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_training_set/20210802-08h12m15sModel_GCN_015_shuttle_train_epoch_001400of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_validation_set/20210802-08h12m15sModel_GCN_015_shuttle_val_epoch_001400of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_training_set/20210802-08h12m15sModel_GCN_015_shuttle_train_epoch_001600of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_validation_set/20210802-08h12m15sModel_GCN_015_shuttle_val_epoch_001600of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_training_set/20210802-08h12m15sModel_GCN_015_shuttle_train_epoch_001800of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_validation_set/20210802-08h12m15sModel_GCN_015_shuttle_val_epoch_001800of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_training_set/20210802-08h12m15sModel_GCN_015_shuttle_train_epoch_002000of2000.png', '/storage/remote/atcremers50/ss21_multiagentcontrol/006_model_output/GCN_015/20210802-08h12m15s/figures_validation_set/20210802-08h12m15sModel_GCN_015_shuttle_val_epoch_002000of2000.png']
epoch400_train_loss: 2500.612600821036
epoch400_final_val_loss: 4571.725408380682
epoch600_train_loss: 2201.8576863606772
epoch600_final_val_loss: 4394.241876775568
epoch800_train_loss: 2075.3223430492258
epoch800_final_val_loss: 4404.997092507102
epoch1000_train_loss: 1907.8646398473668
epoch1000_final_val_loss: 4343.831587357955
epoch1200_train_loss: 2092.0016052811234
epoch1200_final_val_loss: 4140.738725142045
epoch1400_train_loss: 2003.4412957650643
epoch1400_final_val_loss: 4015.613347833807
epoch1600_train_loss: 1836.8867989999276
epoch1600_final_val_loss: 4522.376020951705
epoch1800_train_loss: 1745.136575769495
epoch1800_final_val_loss: 4562.423473011364
epoch2000_train_loss: 1614.6295219703957
epoch2000_final_val_loss: 4626.998357599432
final_train_loss: 1614.6295219703957
final_val_loss: 4626.998357599432
